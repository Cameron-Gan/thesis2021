{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path\n",
    "from os.path import join\n",
    "from os import getcwd, listdir\n",
    "path_to_data = path.join('..', '..', 'data', 'weather')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '..\\\\..\\\\data\\\\weather\\\\Sydney_Airport_Min.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-16-2a11dd624fb1>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdf_min\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath_to_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'Sydney_Airport_Min.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mdf_max\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath_to_data\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'Sydney_Airport_Max.csv'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mdf_max\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Date'\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mto_datetime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf_max\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Year'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'Month'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'Day'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mdf\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mdf_max\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Date'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_max\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Maximum temperature (Degree C)'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdf_min\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'Minimum temperature (Degree C)'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Thesis1\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[0;32m    684\u001B[0m     )\n\u001B[0;32m    685\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 686\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    687\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    688\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Thesis1\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    450\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    451\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 452\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfp_or_buf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    453\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    454\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Thesis1\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    944\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    945\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 946\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    947\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    948\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Thesis1\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1176\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"c\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1177\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"c\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1178\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mCParserWrapper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1179\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1180\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m\"python\"\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\Thesis1\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m   2006\u001B[0m         \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"usecols\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0musecols\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2007\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2008\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mparsers\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTextReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2009\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munnamed_cols\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munnamed_cols\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2010\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mpandas\\_libs\\parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '..\\\\..\\\\data\\\\weather\\\\Sydney_Airport_Min.csv'"
     ]
    }
   ],
   "source": [
    "df_min = pd.read_csv(path.join(path_to_data, 'Sydney_Airport_Min.csv'))\n",
    "df_max = pd.read_csv(path.join(path_to_data, 'Sydney_Airport_Max.csv'))\n",
    "\n",
    "df_max['Date'] = pd.to_datetime(df_max[['Year', 'Month', 'Day']])\n",
    "df = pd.concat([df_max['Date'], df_max['Maximum temperature (Degree C)'], df_min['Minimum temperature (Degree C)']], axis=1)\n",
    "df.set_index('Date')\n",
    "df.to_csv(path.join(path_to_data, 'Sydney_Airport_Temp.csv'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "            Maximum temperature (Degree C)  Minimum temperature (Degree C)\nDate                                                                      \n1939-01-01                             NaN                             NaN\n1939-01-02                             NaN                             NaN\n1939-01-03                             NaN                             NaN\n1939-01-04                             NaN                             NaN\n1939-01-05                             NaN                             NaN\n...                                    ...                             ...\n2021-03-04                            28.8                            16.6\n2021-03-05                            22.9                            18.8\n2021-03-06                            22.5                            18.2\n2021-03-07                            26.5                            16.8\nNaN                                    NaN                            19.0\n\n[30018 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Maximum temperature (Degree C)</th>\n      <th>Minimum temperature (Degree C)</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1939-01-01</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1939-01-02</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1939-01-03</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1939-01-04</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1939-01-05</th>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-03-04</th>\n      <td>28.8</td>\n      <td>16.6</td>\n    </tr>\n    <tr>\n      <th>2021-03-05</th>\n      <td>22.9</td>\n      <td>18.8</td>\n    </tr>\n    <tr>\n      <th>2021-03-06</th>\n      <td>22.5</td>\n      <td>18.2</td>\n    </tr>\n    <tr>\n      <th>2021-03-07</th>\n      <td>26.5</td>\n      <td>16.8</td>\n    </tr>\n    <tr>\n      <th>NaN</th>\n      <td>NaN</td>\n      <td>19.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>30018 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path.join(path_to_data, 'Sydney_Airport_Temp.csv'), index_col=0)\n",
    "df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "            Daily global solar exposure (MJ/m*m)\nDate                                            \n1990-01-01                                  34.4\n1990-01-02                                  29.8\n1990-01-03                                   NaN\n1990-01-04                                  26.7\n1990-01-05                                  31.3\n...                                          ...\n2021-03-03                                  24.2\n2021-03-04                                  24.1\n2021-03-05                                  23.7\n2021-03-06                                  22.3\n2021-03-07                                  10.8\n\n[11389 rows x 1 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Daily global solar exposure (MJ/m*m)</th>\n    </tr>\n    <tr>\n      <th>Date</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1990-01-01</th>\n      <td>34.4</td>\n    </tr>\n    <tr>\n      <th>1990-01-02</th>\n      <td>29.8</td>\n    </tr>\n    <tr>\n      <th>1990-01-03</th>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1990-01-04</th>\n      <td>26.7</td>\n    </tr>\n    <tr>\n      <th>1990-01-05</th>\n      <td>31.3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2021-03-03</th>\n      <td>24.2</td>\n    </tr>\n    <tr>\n      <th>2021-03-04</th>\n      <td>24.1</td>\n    </tr>\n    <tr>\n      <th>2021-03-05</th>\n      <td>23.7</td>\n    </tr>\n    <tr>\n      <th>2021-03-06</th>\n      <td>22.3</td>\n    </tr>\n    <tr>\n      <th>2021-03-07</th>\n      <td>10.8</td>\n    </tr>\n  </tbody>\n</table>\n<p>11389 rows × 1 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_insolation = pd.read_csv(join(path_to_data, 'Adelaide_Airport_Insolation.csv'), index_col=0)\n",
    "df_insolation.index = pd.to_datetime(df_insolation.index)\n",
    "df_insolation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "features = ['Maximum temperature (Degree C)',\n",
    "'Daily global solar exposure (MJ/m*m)',\n",
    "        'previous_day',\n",
    "        'second_previous_day',\n",
    "        'previous_week',\n",
    "        'month',\n",
    "        'dayofweek',\n",
    "        'daily_max']\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "def calculate_residuals(model, features, label):\n",
    "    \"\"\"\n",
    "    Creates predictions on the features with the model and calculates residuals\n",
    "    \"\"\"\n",
    "    predictions = model.predict(features)\n",
    "    df_results = pd.DataFrame({'Actual': label, 'Predicted': predictions})\n",
    "    df_results['Residuals'] = abs(df_results['Actual']) - abs(df_results['Predicted'])\n",
    "\n",
    "    return df_results\n",
    "def linear_assumption(model, features, label):\n",
    "    \"\"\"\n",
    "    Linearity: Assumes that there is a linear relationship between the predictors and\n",
    "               the response variable. If not, either a quadratic term or another\n",
    "               algorithm should be used.\n",
    "    \"\"\"\n",
    "    print('Assumption 1: Linear Relationship between the Target and the Feature', '\\n')\n",
    "\n",
    "    print('Checking with a scatter plot of actual vs. predicted.',\n",
    "           'Predictions should follow the diagonal line.')\n",
    "\n",
    "    # Calculating residuals for the plot\n",
    "    df_results = calculate_residuals(model, features, label)\n",
    "\n",
    "    # Plotting the actual vs predicted values\n",
    "    sns.lmplot(x='Actual', y='Predicted', data=df_results, fit_reg=False, size=5)\n",
    "\n",
    "    # Plotting the diagonal line\n",
    "    line_coords = np.arange(df_results.min().min(), df_results.max().max())\n",
    "    plt.plot(line_coords, line_coords,  # X and y points\n",
    "             color='darkorange', linestyle='--')\n",
    "    plt.title('Actual vs. Predicted')\n",
    "    plt.show()\n",
    "# def normal_errors_assumption(model, features, label, p_value_thresh=0.05):\n",
    "#     \"\"\"\n",
    "#     Normality: Assumes that the error terms are normally distributed. If they are not,\n",
    "#     nonlinear transformations of variables may solve this.\n",
    "#\n",
    "#     This assumption being violated primarily causes issues with the confidence intervals\n",
    "#     \"\"\"\n",
    "#     from statsmodels.stats.diagnostic import normal_ad\n",
    "#     print('Assumption 2: The error terms are normally distributed', '\\n')\n",
    "#\n",
    "#     # Calculating residuals for the Anderson-Darling test\n",
    "#     df_results = calculate_residuals(model, features, label)\n",
    "#\n",
    "#     print('Using the Anderson-Darling test for normal distribution')\n",
    "#\n",
    "#     # Performing the test on the residuals\n",
    "#     p_value = normal_ad(df_results['Residuals'])[1]\n",
    "#     print('p-value from the test - below 0.05 generally means non-normal:', p_value)\n",
    "#\n",
    "#     # Reporting the normality of the residuals\n",
    "#     if p_value < p_value_thresh:\n",
    "#         print('Residuals are not normally distributed')\n",
    "#     else:\n",
    "#         print('Residuals are normally distributed')\n",
    "#\n",
    "#     # Plotting the residuals distribution\n",
    "#     plt.subplots(figsize=(12, 6))\n",
    "#     plt.title('Distribution of Residuals')\n",
    "#     sns.distplot(df_results['Residuals'])\n",
    "#     plt.show()\n",
    "#\n",
    "#     print()\n",
    "#     if p_value > p_value_thresh:\n",
    "#         print('Assumption satisfied')\n",
    "#     else:\n",
    "#         print('Assumption not satisfied')\n",
    "#         print()\n",
    "#         print('Confidence intervals will likely be affected')\n",
    "#         print('Try performing nonlinear transformations on variables')\n",
    "regr = linear_model.LinearRegression()\n",
    "regr.fit(X_train, y_train)\n",
    "linear_assumption(regr, X_train, y_train)\n",
    "print(regr.score(X_test,y_test))\n",
    "prediction = regr.predict(y_test)\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,4))\n",
    "d['2019-06':'2019-12'].total_use_wo_load.plot(ax=ax)\n",
    "sns.lineplot(y=prediction, x=d['2019-06':'2019-12'].index)\n",
    "plt.show()\n",
    "prediction = regr.predict(X)\n",
    "fig, ax = plt.subplots(1,1, figsize=(12,4))\n",
    "sns.lineplot(y=y, x=y.index)\n",
    "sns.lineplot(y=prediction, x=y.index)\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-16601492",
   "language": "python",
   "display_name": "PyCharm (Thesis1)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}